{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfdb996",
   "metadata": {},
   "source": [
    "# Chapter 6\n",
    "\n",
    "## Tuning hyperparameters of clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "processed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Intro\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "special-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "\n",
    "custom_schema = StructType([\n",
    "    StructField(\"Make\", StringType(), True),\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Vehicle Class\", StringType(), True),\n",
    "    StructField(\"Cylinders\", DoubleType(), True),\n",
    "    StructField(\"Transmission\", StringType(), True),\n",
    "    StructField(\"Fuel Type\", StringType(), True),\n",
    "    StructField(\"Fuel Consumption City (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Hwy (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (mpg)\", DoubleType(), True),\n",
    "    StructField(\"CO2\", DoubleType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_data = spark.read.format(\"csv\")\\\n",
    "    .schema(custom_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"./static/CO2_Emissions_Canada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "raised-equality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:12:01 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intermediate-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_only_continues_values = {'Fuel Consumption City (L/100 km)':0}\n",
    "#                               \"Fuel Consumption Hwy (L/100 km)\",\n",
    "#         \"Fuel Consumption Comb (L/100 km)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cultural-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_data = co2_data.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mature-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "co2_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "level-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:13:53 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-sellers",
   "metadata": {},
   "source": [
    "# Prep the data for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-embassy",
   "metadata": {},
   "source": [
    "turn the feature columns into one indexed column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "\n",
    "cols = [\"Make\", \"Model\", \"Vehicle Class\",\"Cylinders\",\"Transmission\",\"Fuel Type\",\n",
    "        \"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
    "        \"Fuel Consumption Comb (L/100 km)\",\"Fuel Consumption Comb (mpg)\"]\n",
    "\n",
    "cols_only_continues = [\"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
    "        \"Fuel Consumption Comb (L/100 km)\"]\n",
    "\n",
    "hasher = FeatureHasher(outputCol=\"hashed_features\", inputCols=cols_only_continues)\n",
    "data = hasher.transform(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hairy-mountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|hashed_features                              |\n",
      "+---------------------------------------------+\n",
      "|(262144,[38607,109231,228390],[0.0,9.9,6.7]) |\n",
      "|(262144,[38607,109231,228390],[0.0,11.2,7.7])|\n",
      "|(262144,[38607,109231,228390],[0.0,6.0,5.8]) |\n",
      "|(262144,[38607,109231,228390],[0.0,12.7,9.1])|\n",
      "|(262144,[38607,109231,228390],[0.0,12.1,8.7])|\n",
      "+---------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:14:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "data.select(\"hashed_features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "closed-boulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:14:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(hashed_features=SparseVector(262144, {38607: 0.0, 109231: 9.9, 228390: 6.7}))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\"hashed_features\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vulnerable-right",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|hashed_features                              |\n",
      "+---------------------------------------------+\n",
      "|(262144,[38607,109231,228390],[0.0,9.9,6.7]) |\n",
      "|(262144,[38607,109231,228390],[0.0,11.2,7.7])|\n",
      "|(262144,[38607,109231,228390],[0.0,6.0,5.8]) |\n",
      "|(262144,[38607,109231,228390],[0.0,12.7,9.1])|\n",
      "|(262144,[38607,109231,228390],[0.0,12.1,8.7])|\n",
      "+---------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:15:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "data.select(\"hashed_features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stupid-modeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-roots",
   "metadata": {},
   "source": [
    "# Time for selecting the most meaningful features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "breeding-christmas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:19:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (mpg)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km), CO2\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:19:01 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/11 19:19:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (mpg)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km), CO2\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:19:22 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "\n",
    "selector = UnivariateFeatureSelector(outputCol=\"selectedFeatures\", featuresCol=\"hashed_features\", labelCol=\"CO2\")\n",
    "\n",
    "selector.setFeatureType(\"continuous\")\n",
    "selector.setLabelType(\"continuous\")\n",
    "\n",
    "model = selector.fit(data)\n",
    "data = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99aee53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|selectedFeatures       |\n",
      "+-----------------------+\n",
      "|(50,[48,49],[9.9,6.7]) |\n",
      "|(50,[48,49],[11.2,7.7])|\n",
      "|(50,[48,49],[6.0,5.8]) |\n",
      "|(50,[48,49],[12.7,9.1])|\n",
      "|(50,[48,49],[12.1,8.7])|\n",
      "+-----------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:23:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "data.select(\"selectedFeatures\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-moscow",
   "metadata": {},
   "source": [
    " ## Tryout LDA clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:24:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:24:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:24:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:24:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "\n",
    "lda = LDA(k=2, seed=1, optimizer=\"em\", featuresCol=\"selectedFeatures\")\n",
    "lda.setMaxIter(100)\n",
    "\n",
    "\n",
    "lda.clear(lda.maxIter)\n",
    "lda_model = lda.fit(data)\n",
    "lda_model.setSeed(1)\n",
    "\n",
    "# check if the model itself is distributed across Spark executors\n",
    "lda_model.isDistributed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pretty-appearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+\n",
      "|topic|termIndices|         termWeights|\n",
      "+-----+-----------+--------------------+\n",
      "|    0|   [48, 49]|[0.58104675033297...|\n",
      "|    1|   [48, 49]|[0.58168999987474...|\n",
      "+-----+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model.describeTopics().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "configured-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "embedded-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_predictions = lda_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "respected-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      " |-- selectedFeatures: vector (nullable = true)\n",
      " |-- topicDistribution: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exotic-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|topicDistribution                       |\n",
      "+----------------------------------------+\n",
      "|[0.4999989319581025,0.5000010680418975] |\n",
      "|[0.5000014415937216,0.49999855840627844]|\n",
      "+----------------------------------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:24:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:24:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "lda_predictions.select(\"topicDistribution\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-brake",
   "metadata": {},
   "source": [
    "# Tryout KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "creative-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:25:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:25:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:25:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:25:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'euclidean'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "\n",
    "kmeans = KMeans(k=3)\n",
    "kmeans.setSeed(10)\n",
    "kmeans.setFeaturesCol(\"selectedFeatures\")\n",
    "\n",
    "kmeans_model = kmeans.fit(data)\n",
    "kmeans_model.getDistanceMeasure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "gothic-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predictions = kmeans_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "wired-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         2|\n",
      "|         2|\n",
      "+----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:25:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "kmeans_predictions.select(\"prediction\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "proprietary-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         1|\n",
      "|         2|\n",
      "|         0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:25:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "kmeans_predictions.select(\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "durable-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = kmeans_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "technological-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.cluster.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-spain",
   "metadata": {},
   "source": [
    "# Tryout GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dimensional-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:25:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:25:44 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "25/10/11 19:25:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(k=42, tol=0.01, seed=10, featuresCol=\"selectedFeatures\", maxIter=100)\n",
    "gm_model = gm.fit(data)\n",
    "\n",
    "gm_predictions = gm_model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-wonder",
   "metadata": {},
   "source": [
    "Print the model params using `explainParams()` functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "electric-chaos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\\n'\n",
      " 'featuresCol: features column name. (default: features, current: '\n",
      " 'selectedFeatures)\\n'\n",
      " 'k: Number of independent Gaussians in the mixture model. Must be > 1. '\n",
      " '(default: 2, current: 42)\\n'\n",
      " 'maxIter: max number of iterations (>= 0). (default: 100, current: 100)\\n'\n",
      " 'predictionCol: prediction column name. (default: prediction)\\n'\n",
      " 'probabilityCol: Column name for predicted class conditional probabilities. '\n",
      " 'Note: Not all models output well-calibrated probability estimates! These '\n",
      " 'probabilities should be treated as confidences, not precise probabilities. '\n",
      " '(default: probability)\\n'\n",
      " 'seed: random seed. (default: 3052518430336294888, current: 10)\\n'\n",
      " 'tol: the convergence tolerance for iterative algorithms (>= 0). (default: '\n",
      " '0.01, current: 0.01)\\n'\n",
      " 'weightCol: weight column name. If this is not set or empty, we treat all '\n",
      " 'instance weights as 1.0. (undefined)')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "params = gm_model.explainParams()\n",
    "pp.pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-depth",
   "metadata": {},
   "source": [
    "# Constructing - The Pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "blessed-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:26:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (mpg)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km), CO2\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:26:12 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/11 19:26:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (mpg)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km), CO2\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:26:39 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/11 19:26:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:26:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[hasher, selector, gm])\n",
    "pipeline_model = pipeline.fit(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adult-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_by_pipeline = pipeline_model.transform(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "necessary-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      " |-- selectedFeatures: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_by_pipeline.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-serum",
   "metadata": {},
   "source": [
    "## Evaluating clustering models\n",
    "\n",
    "Notice we are not using this evaluator for LDA since it outputs topicDistribution and not one numeric prdiction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "european-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:29:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:29:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:29:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans: 0.6791002214675337\n",
      "GM: -0.1517797715036008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:29:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator(featuresCol='selectedFeatures')\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "\n",
    "#evaluate with eucliden distance\n",
    "print(\"kmeans: \"+str(evaluator.evaluate(kmeans_predictions)))\n",
    "print(\"GM: \"+ str(evaluator.evaluate(gm_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "expressed-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.isLargerBetter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "silver-instrument",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:29:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:29:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:29:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans: -0.07958234502129219\n",
      "GM: -0.19012403274289733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:29:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "evaluator.setDistanceMeasure(\"cosine\")\n",
    "print(\"kmeans: \"+str(evaluator.evaluate(kmeans_predictions)))\n",
    "print(\"GM: \"+ str(evaluator.evaluate(gm_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "novel-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.isLargerBetter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "mysterious-press",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"distanceMeasure: The distance measure. Supported options: 'squaredEuclidean' and 'cosine'. (default: squaredEuclidean, current: cosine)\\nfeaturesCol: features column name. (default: features, current: selectedFeatures)\\nmetricName: metric name in evaluation (silhouette) (default: silhouette)\\npredictionCol: prediction column name. (default: prediction, current: prediction)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.explainParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-saudi",
   "metadata": {},
   "source": [
    "### Since evaluator output for `isLargerBetter` was true, we can define that kmeans algorithm produced a better model than GM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-genome",
   "metadata": {},
   "source": [
    "# Hyperparameters and Tuning experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:30:24 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:30:25 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:30:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:30:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:30:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:30:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]).build()\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True, parallelism=1, seed=42)\n",
    "\n",
    "tvs_model = tvs.fit(data)\n",
    "tvs_model.getTrainRatio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "skilled-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06270405194965402, -0.06402059325959049, -0.06402059325959049]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "interesting-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
    "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "transsexual-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06270405194965402, -0.06402059325959049, -0.06402059325959049]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "tested-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:30:59 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:00 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
    "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']) \\\n",
    "        .addGrid(evaluator.distanceMeasure, ['euclidean','cosine']).build()\n",
    "\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True, parallelism=1, seed=42, trainRatio=0.8)\n",
    "tvs_model = tvs.fit(data)\n",
    "tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-fisher",
   "metadata": {},
   "source": [
    "## Adding evaluator to the grid params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:31:40 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:41 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:31:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769,\n",
       " -0.06292946960479909,\n",
       " -0.06292946960479909,\n",
       " 0.5520132682136769,\n",
       " 0.5520132682136769]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
    "\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
    "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']) \\\n",
    "        .addGrid(evaluator.distanceMeasure, ['euclidean','cosine'])\\\n",
    "        .baseOn({kmeans.featuresCol: 'selectedFeatures'}) \\\n",
    "        .build()\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True, parallelism=1, seed=42, trainRatio=0.8)\n",
    "\n",
    "tvs_model = tvs.fit(data)\n",
    "tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "swedish-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       " KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.subModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "amended-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_models = tvs_model.subModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-harris",
   "metadata": {},
   "source": [
    "# Advanced Split\n",
    "\n",
    "the subModels are printed here as an example, do not use for real systems!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "worthy-arrest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:32:04 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:04 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:06 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:07 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:08 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:09 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/11 19:32:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50],\n",
       " [KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50],\n",
       " [KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50,\n",
       "  KMeansModel: uid=KMeans_875c43040254, k=3, distanceMeasure=cosine, numFeatures=50]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "                           collectSubModels=True,  parallelism=2, numFolds=3)\n",
    "\n",
    "cv_model = cv.fit(data)\n",
    "cv_model.subModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "defensive-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_model.subModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "novel-relay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_model.subModels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aboriginal-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-0.0801749698018508),\n",
       " np.float64(-0.0801749698018508),\n",
       " np.float64(0.6000525675573857),\n",
       " np.float64(0.6000525675573857),\n",
       " np.float64(-0.0801749698018508),\n",
       " np.float64(-0.0801749698018508),\n",
       " np.float64(0.6000525675573857),\n",
       " np.float64(0.6000525675573857),\n",
       " np.float64(-0.0801749698018508),\n",
       " np.float64(-0.0801749698018508),\n",
       " np.float64(0.6000525675573857),\n",
       " np.float64(0.6000525675573857)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9feeb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|    selectedFeatures|prediction|\n",
      "+--------------------+----------+\n",
      "|(50,[48,49],[9.9,...|         0|\n",
      "|(50,[48,49],[11.2...|         2|\n",
      "|(50,[48,49],[6.0,...|         1|\n",
      "|(50,[48,49],[12.7...|         2|\n",
      "|(50,[48,49],[12.1...|         2|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 19:34:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from cross-validation\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_predictions = best_model.transform(data)\n",
    "\n",
    "# Show predictions from the best model\n",
    "best_predictions.select(\"selectedFeatures\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ee282eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best average metric: 0.6000525675573857\n",
      "Best parameter combination index: 2\n"
     ]
    }
   ],
   "source": [
    "# Get the best average metric across all folds\n",
    "best_avg_metric = max(cv_model.avgMetrics)\n",
    "print(f\"Best average metric: {best_avg_metric}\")\n",
    "\n",
    "# Find which parameter combination achieved this\n",
    "best_param_index = cv_model.avgMetrics.index(best_avg_metric)\n",
    "print(f\"Best parameter combination index: {best_param_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6ba5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation best: 0.6000525675573857\n",
      "Train-Validation Split best: 0.5520132682136769\n"
     ]
    }
   ],
   "source": [
    "# Compare CrossValidator vs TrainValidationSplit\n",
    "print(\"Cross-Validation best:\", max(cv_model.avgMetrics))\n",
    "print(\"Train-Validation Split best:\", max(tvs_model.validationMetrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b72fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-with-spark-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
