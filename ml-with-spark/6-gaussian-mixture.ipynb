{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modern-klein",
   "metadata": {},
   "source": [
    "# Chapter 6\n",
    "\n",
    "## Gaussian mixture pipeline\n",
    "\n",
    "Use Machine Learning Methods to cluster cars and their CO2 emission. \n",
    "Dataset by Kaggle. More information can be found [here](https://www.kaggle.com/debajyotipodder/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/12 17:56:00 WARN Utils: Your hostname, Gabriels-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 10.40.1.32 instead (on interface en0)\n",
      "25/10/12 17:56:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/12 17:56:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Intro\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "special-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "\n",
    "custom_schema = StructType([\n",
    "    StructField(\"Make\", StringType(), True),\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Vehicle Class\", StringType(), True),\n",
    "    StructField(\"Cylinders\", DoubleType(), True),\n",
    "    StructField(\"Transmission\", StringType(), True),\n",
    "    StructField(\"Fuel Type\", StringType(), True),\n",
    "    StructField(\"Fuel Consumption City (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Hwy (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (L/100 km)\", DoubleType(), True),\n",
    "    StructField(\"Fuel Consumption Comb (mpg)\", DoubleType(), True),\n",
    "    StructField(\"CO2\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "green-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_data = spark.read.format(\"csv\")\\\n",
    "    .schema(custom_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"./static/CO2_Emissions_Canada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raised-equality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/12 17:57:05 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cultural-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_data = co2_data.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mature-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "co2_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "level-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/12 17:57:14 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 12, schema size: 11\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
       " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-sellers",
   "metadata": {},
   "source": [
    "# Build Hasher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-embassy",
   "metadata": {},
   "source": [
    "Turn the feature columns into one indexed column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "\n",
    "cols_only_continues = [\n",
    "        \"Fuel Consumption City (L/100 km)\", \n",
    "        \"Fuel Consumption Hwy (L/100 km)\",\n",
    "        \"Fuel Consumption Comb (L/100 km)\",\n",
    "]\n",
    "\n",
    "hasher = FeatureHasher(\n",
    "    outputCol=\"hashed_features\", inputCols=cols_only_continues\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-roots",
   "metadata": {},
   "source": [
    "# Build Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "breeding-christmas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnivariateFeatureSelector_5912b96f9673"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "\n",
    "selector = UnivariateFeatureSelector(\n",
    "    outputCol=\"selectedFeatures\", featuresCol=\"hashed_features\", labelCol=\"CO2\"\n",
    ")\n",
    "\n",
    "selector.setFeatureType(\"continuous\")\n",
    "selector.setLabelType(\"continuous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-spain",
   "metadata": {},
   "source": [
    "# Create GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(k=42, tol=0.01, seed=10, featuresCol=\"selectedFeatures\", maxIter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-depth",
   "metadata": {},
   "source": [
    "# Constructing - The Pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "blessed-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/12 18:14:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (mpg)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km), CO2\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/12 18:14:49 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/12 18:14:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (mpg)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km), CO2\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/12 18:15:16 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/12 18:15:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n",
      "25/10/12 18:15:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Fuel Type, Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km)\n",
      " Schema: Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km), Fuel Consumption Comb (L/100 km)\n",
      "Expected: Fuel Consumption City (L/100 km) but found: Fuel Type\n",
      "CSV file: file:///Users/gafnts/Documents/Github/ml-with-spark/ml-with-spark/static/CO2_Emissions_Canada.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[hasher, selector, gm])\n",
    "\n",
    "model = pipeline.fit(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adult-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_by_pipeline = model.transform(co2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "necessary-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Vehicle Class: string (nullable = true)\n",
      " |-- Cylinders: double (nullable = false)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Fuel Type: string (nullable = true)\n",
      " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
      " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
      " |-- CO2: double (nullable = false)\n",
      " |-- hashed_features: vector (nullable = true)\n",
      " |-- selectedFeatures: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_by_pipeline.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-layout",
   "metadata": {},
   "source": [
    "# Persisting the pipeline to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_with_pip = \"./tmp/pip_model\"\n",
    "model.write().overwrite().save(path_model_with_pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-addition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-with-spark-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
